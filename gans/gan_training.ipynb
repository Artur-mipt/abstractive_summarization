{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as sps\n",
    "import nlp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.seq2seq_generator import Seq2Seq, Encoder, Decoder\n",
    "from src.cnn_discriminator import CNNDiscriminator\n",
    "from src.utils import *\n",
    "from src.dataset import Dataset, Padder\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 670 ms, sys: 20.2 ms, total: 690 ms\n",
      "Wall time: 690 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if dataset_name == 'cnn':\n",
    "    train_dataset = nlp.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\")\n",
    "    val_dataset = nlp.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"validation\")\n",
    "    test_dataset = nlp.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test\")\n",
    "    train_articles = [item['article'] for item in train_dataset]\n",
    "    train_highlights = [item['highlights'] for item in train_dataset]\n",
    "    val_articles = [item['article'] for item in val_dataset]\n",
    "    val_highlights = [item['highlights'] for item in val_dataset]\n",
    "elif dataset_name == 'news':\n",
    "    news = pd.read_csv('data/news_summary.csv')\n",
    "    news.headlines = [process_str(s) for s in news.headlines]\n",
    "    news.text = [process_str(s) for s in news.text]\n",
    "    X_train, X_test = train_test_split(news, test_size=0.3,\n",
    "                                       random_state=42)\n",
    "    train_articles = X_train.text.values\n",
    "    train_highlights = X_train.headlines.values\n",
    "    val_articles = X_test.text.values\n",
    "    val_highlights = X_test.headlines.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. sentencepiece model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 2.62 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if train_new_model:\n",
    "    with open('data/news_texts.txt', 'a') as f:\n",
    "        for article in tqdm(train_articles):\n",
    "            f.write(article + '\\n')\n",
    "        for highlight in tqdm(train_highlights):\n",
    "            f.write(highlight + '\\n')\n",
    "        for article in tqdm(val_articles):\n",
    "            f.write(article + '\\n')\n",
    "        for highlight in tqdm(val_highlights):\n",
    "            f.write(highlight + '\\n')\n",
    "            \n",
    "    spm.SentencePieceTrainer.train(input='data/news_texts.txt',\n",
    "                                   model_prefix='news10k',\n",
    "                                   vocab_size=10000,\n",
    "                                   pad_id=0,\n",
    "                                   bos_id=1,\n",
    "                                   eos_id=2,\n",
    "                                   unk_id=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "sp_modelname = f'sentencepiece_models/news{int(vocab_size/1000)}k.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file=sp_modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_articles, train_highlights, sp=sp)\n",
    "val_dataset = Dataset(val_articles, val_highlights, sp=sp)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128,\n",
    "                              collate_fn=Padder(), shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128,\n",
    "                            collate_fn=Padder(), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([97, 128])\n",
      "torch.Size([23, 128])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch[0].size())\n",
    "    print(batch[1].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = vocab_size\n",
    "OUTPUT_DIM = vocab_size\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 3\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "G = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = 10000\n",
    "padding_idx = 0\n",
    "D = CNNDiscriminator(embed_dim=emb_dim,\n",
    "                     vocab_size=vocab_size,\n",
    "                     num_classes=2,\n",
    "                     filter_sizes=[2, 3, 3],\n",
    "                     num_filters=200,\n",
    "                     padding_idx=padding_idx).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. generator pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "lr = 1e-4\n",
    "opt = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "n_epochs = 40\n",
    "\n",
    "epoch_losses = []\n",
    "val_losses = []\n",
    "iter_num = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:23,  6.42it/s]\n",
      "2it [00:00, 16.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss: 7.088446982757001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 val loss: 6.885697969329587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: issssssssss\n",
      "truth: india are smelling blood we will show them great respect langer\n",
      "predicted: issssssssss\n",
      "truth: us man awarded 4 8 crore after beer burns his organs\n",
      "predicted: issssssssss\n",
      "truth: nasa spacecraft landed on mars with names of over 1l indians\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.39it/s]\n",
      "2it [00:00, 17.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train loss: 6.862518388081372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 val loss: 6.859455553126333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: isssssssssss\n",
      "truth: f1 driver crashes after race ends rides back on another car\n",
      "predicted: issssssssss\n",
      "truth: would like to work with ranbir kapoor again rajkumar hirani\n",
      "predicted: isssssssssss\n",
      "truth: fake news of srk s death emerges on european news channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.41it/s]\n",
      "2it [00:00, 16.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 train loss: 6.839442179898075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 val loss: 6.847000865794784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: issssssssss\n",
      "truth: barcelona become world s 1st team to spend 500 million on wages\n",
      "predicted: isssssssssss\n",
      "truth: game of thrones puts women at the forefront gwendoline\n",
      "predicted: isssssssssss\n",
      "truth: farmers dump vegetables spill milk on roads during protest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.39it/s]\n",
      "2it [00:00, 16.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 train loss: 6.815205231554693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 val loss: 6.803446948780672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: manssssssssss\n",
      "truth: french singer barbara weldens dies on stage during concert\n",
      "predicted: isssssssss\n",
      "truth: first look poster of sushant kriti s raabta unveiled\n",
      "predicted: isssssssss\n",
      "truth: delhi cm discharged in defamation case over thulla remark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:25,  6.34it/s]\n",
      "2it [00:00, 16.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 train loss: 6.745788951479461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 val loss: 6.744473919878645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: i tossssssss\n",
      "truth: enough evidence to convict syrian prez of war crimes un\n",
      "predicted: usssssssssss\n",
      "truth: sledging is a fun part of the game aus coach justin langer\n",
      "predicted: i tossssssss\n",
      "truth: whatsapp must have grievance officer in india it min to ceo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:25,  6.32it/s]\n",
      "2it [00:00, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 train loss: 6.690013065958411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 val loss: 6.711893868306631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: mansssssssss\n",
      "truth: b luru police ask people to wear helmets share 10 secs challenge\n",
      "predicted: ussssssssss\n",
      "truth: india are smelling blood we will show them great respect langer\n",
      "predicted: i tossssssss\n",
      "truth: satya pal malik sworn in as governor of bihar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.37it/s]\n",
      "2it [00:00, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 train loss: 6.649639253915395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 val loss: 6.678534217136169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: mansssssssss\n",
      "truth: b luru police ask people to wear helmets share 10 secs challenge\n",
      "predicted: issssssssss\n",
      "truth: soldiers to face action for disrespecting militants bodies\n",
      "predicted: indiassssssssss\n",
      "truth: 3 075 grooms got married in bihar at gunpoint in 2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.37it/s]\n",
      "2it [00:00, 16.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 train loss: 6.599526145593907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 val loss: 6.626243485622962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: issssssssss\n",
      "truth: threat to my life claims aimim leader akbaruddin owaisi\n",
      "predicted: usssssssssss\n",
      "truth: 4 missiles fired into pakistan from afghanistan\n",
      "predicted: india sssssssssss\n",
      "truth: aus ke score par laga gst bhaari pad gaya sehwag on india s loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.36it/s]\n",
      "2it [00:00, 16.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 train loss: 6.528411806640448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 16.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 val loss: 6.553303218954749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: ussssssssss\n",
      "truth: social media giants are silencing millions of people trump\n",
      "predicted: manssssssssss\n",
      "truth: b luru police ask people to wear helmets share 10 secs challenge\n",
      "predicted: india ssssssssssss\n",
      "truth: aus ke score par laga gst bhaari pad gaya sehwag on india s loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:25,  6.28it/s]\n",
      "2it [00:00, 16.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 train loss: 6.443201536030165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 val loss: 6.485739276498069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: pm modissssssss\n",
      "truth: pm modi to attend brics summit in china\n",
      "predicted: scientistssssssssss\n",
      "truth: online volunteers help find star that exploded 97 cr yrs ago\n",
      "predicted: us tossssssss\n",
      "truth: amazon must pay real costs and taxes now donald trump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.37it/s]\n",
      "2it [00:00, 16.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 train loss: 6.37056450782891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 val loss: 6.4274803370440265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: i tossssssss\n",
      "truth: sports can t be run by bureaucrats sports minister rathore\n",
      "predicted: trump koreassssssss\n",
      "truth: social media giants are silencing millions of people trump\n",
      "predicted: google tossssssss\n",
      "truth: amazon must pay real costs and taxes now donald trump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:25,  6.33it/s]\n",
      "2it [00:00, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 train loss: 6.308527766924425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 val loss: 6.377452556673684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: i wassssssssss\n",
      "truth: de villiers hid love letters he wrote in his house s roof\n",
      "predicted: ssssssssss\n",
      "truth: csk pacer lungi reveals he used to sell peanuts on roadside\n",
      "predicted: delhisssssss in in\n",
      "truth: docs chant mantra for hours to bring down deaths in hospital\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:25,  6.30it/s]\n",
      "2it [00:00, 16.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 train loss: 6.254474636126617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 val loss: 6.3524874404720375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: i to to to to to to toss\n",
      "truth: india are smelling blood we will show them great respect langer\n",
      "predicted: pm modisssssssss\n",
      "truth: kartarpur corridor atonement for mistake made in 1947 pm modi\n",
      "predicted: man manssssssss\n",
      "truth: italian nurse jailed for calming newborn with morphine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.35it/s]\n",
      "2it [00:00, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 train loss: 6.20216066003815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 val loss: 6.299816197073922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: govt tos to to to to to toss\n",
      "truth: delhi metro moves sc against 60 crore payment to rinfra arm\n",
      "predicted: man year oldedededingingss in\n",
      "truth: scolded for using phone mumbai teen hangs self dies in hospital\n",
      "predicted: trump sssssssss\n",
      "truth: enough evidence to convict syrian prez of war crimes un\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.35it/s]\n",
      "2it [00:00, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 train loss: 6.156431270891781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 val loss: 6.265845449921933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: bjpsssssssssss\n",
      "truth: kerala treating sabarimala pilgrims like gulag inmates shah\n",
      "predicted: i t t to to tosssss\n",
      "truth: india are smelling blood we will show them great respect langer\n",
      "predicted: startup startup startup startup startup startup raises raises\n",
      "truth: car rental startup zoomcar raises 40 million in series c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.39it/s]\n",
      "2it [00:00, 16.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 train loss: 6.114098820702955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 val loss: 6.2437677745561295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: 2 killedededs in in in in in\n",
      "truth: 20 yr old killed in clashes after eid prayers in kashmir\n",
      "predicted: sc courtsssssss case\n",
      "truth: delhi cm discharged in defamation case over thulla remark\n",
      "predicted: apple to to to to to to to to to\n",
      "truth: amazon to test one hour delivery for fashion show clothes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:25,  6.34it/s]\n",
      "2it [00:00, 16.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 train loss: 6.070729208047935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 val loss: 6.216702288475823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: videoassssss in in in\n",
      "truth: french singer barbara weldens dies on stage during concert\n",
      "predicted: ussssssss in in\n",
      "truth: 4 missiles fired into pakistan from afghanistan\n",
      "predicted: man yr old girlss foringingss\n",
      "truth: scolded for using phone mumbai teen hangs self dies in hospital\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.39it/s]\n",
      "2it [00:00, 16.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 train loss: 6.031909400882344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 val loss: 6.181861846622487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: man yr oldss for foringingings\n",
      "truth: scolded for using phone mumbai teen hangs self dies in hospital\n",
      "predicted: 2 killed in in in in in in in in in\n",
      "truth: 20 yr old killed in clashes after eid prayers in kashmir\n",
      "predicted: no t t to to to pm pms\n",
      "truth: modi is a contractor of social welfare rss chief bhagwat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:25,  6.33it/s]\n",
      "2it [00:00, 16.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 train loss: 5.99396507903397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 val loss: 6.158686655904578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: muslimsssssssss\n",
      "truth: cbi planted witnesses in aarushi murder case allahabad hc\n",
      "predicted: nasa ssssss in in in\n",
      "truth: minor solar flare expected to hit earth today cause auroras\n",
      "predicted: i t ts tos i isssss\n",
      "truth: i never think about what i should ve done differently kajol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.34it/s]\n",
      "2it [00:00, 16.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 train loss: 5.952022083960344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 16.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 val loss: 6.1465697474751195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: man manssssssss\n",
      "truth: suffering for no fault driver who let langur control steering\n",
      "predicted: sachin tendulkar seded s s s s\n",
      "truth: sachin tendulkar attends krunal pandya s wedding in mumbai\n",
      "predicted: salmanssss in from from s\n",
      "truth: received best compliment from dilip kumar for black big b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.35it/s]\n",
      "2it [00:00, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 train loss: 5.916264149314712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 val loss: 6.112096998193336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: 3 yearsssss in in in in in\n",
      "truth: 3 075 grooms got married in bihar at gunpoint in 2016\n",
      "predicted: i is to to to ranbir ranbir on ranb\n",
      "truth: would like to work with ranbir kapoor again rajkumar hirani\n",
      "predicted: srksalmanssssssssss\n",
      "truth: amitabh aishwarya submit documents in panama papers probe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.35it/s]\n",
      "2it [00:00, 16.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 train loss: 5.878172752056941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 val loss: 6.0891910880518365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: bjp cmsssssssss\n",
      "truth: kerala treating sabarimala pilgrims like gulag inmates shah\n",
      "predicted: us of of of of ofedededed\n",
      "truth: event guests sing you ll never walk alone over terror threat\n",
      "predicted: i s ssededededededed\n",
      "truth: fake news of srk s death emerges on european news channel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.38it/s]\n",
      "2it [00:00, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 train loss: 5.842356841655558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 val loss: 6.067246124813144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: 2 killed in in in in in in in in\n",
      "truth: gorkhaland supporter killed in police firing in darjeeling\n",
      "predicted: world sssssssss in\n",
      "truth: 27 hurun rich list billionaires passed away last year\n",
      "predicted: mansssssssss\n",
      "truth: man turns his car into a drivable hot tub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.38it/s]\n",
      "2it [00:00, 16.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 train loss: 5.807628951698507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 val loss: 6.049769565966317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: videossssss in in in in\n",
      "truth: french singer barbara weldens dies on stage during concert\n",
      "predicted: i to to to to in s s s s\n",
      "truth: pak will become asian tiger under imran khan shoaib akhtar\n",
      "predicted: i toed to to to for for for fors\n",
      "truth: akmal should be ashamed for being sent back to pak waqar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.36it/s]\n",
      "2it [00:00, 16.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 train loss: 5.774549917116952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 val loss: 6.026976798229321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: iir to to to ranbir ranbir ranbir\n",
      "truth: would like to work with ranbir kapoor again rajkumar hirani\n",
      "predicted: i sssss in in inssss\n",
      "truth: received best compliment from dilip kumar for black big b\n",
      "predicted: ex ministerssss in in in in\n",
      "truth: satya pal malik sworn in as governor of bihar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.37it/s]\n",
      "2it [00:00, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 train loss: 5.743990244294985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 val loss: 6.001842843053108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: salman khanssssssssss\n",
      "truth: amitabh aishwarya submit documents in panama papers probe\n",
      "predicted: sunnyasssssssssss\n",
      "truth: game of thrones puts women at the forefront gwendoline\n",
      "predicted: sachin tendulkar ss s s s s s\n",
      "truth: sachin tendulkar attends krunal pandya s wedding in mumbai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.38it/s]\n",
      "2it [00:00, 16.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 train loss: 5.7115317847532125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 val loss: 5.98255180544511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: man manss crore crore crore crore worth caring\n",
      "truth: us man awarded 4 8 crore after beer burns his organs\n",
      "predicted: i t t t i i i i issss\n",
      "truth: i never think about what i should ve done differently kajol\n",
      "predicted: kohliis kohliiiiiiiii\n",
      "truth: aus ke score par laga gst bhaari pad gaya sehwag on india s loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [01:24,  6.37it/s]\n",
      "2it [00:00, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 train loss: 5.679177348815882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 val loss: 5.967853670403554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: i shouldsed for for for foring pak\n",
      "truth: akmal should be ashamed for being sent back to pak waqar\n",
      "predicted: mansssssssss\n",
      "truth: us thieves try to steal tv return it as it didn t fit in car\n",
      "predicted: man manss foringinginginging\n",
      "truth: italian nurse jailed for calming newborn with morphine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:05,  6.31it/s]"
     ]
    }
   ],
   "source": [
    "for epoch_idx in range(n_epochs):\n",
    "    G.train()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, data_input in tqdm(enumerate(train_dataloader), position=0, leave=True):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        opt.zero_grad()\n",
    "        out = G(article, highlight, teacher_forcing_ratio=0.2)\n",
    "        loss = criterion(out.permute(1, 2, 0), highlight.permute(1, 0))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.data.item() * article.size(1)\n",
    "        iter_num += 1\n",
    "        writer.add_scalar('Loss/train', loss.data.item(), iter_num)\n",
    "    \n",
    "    epoch_losses.append(total_loss / len(train_dataset))\n",
    "    print(f'epoch {epoch_idx} train loss: {epoch_losses[-1]}')\n",
    "    \n",
    "    G.eval()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, data_input in tqdm(enumerate(val_dataloader), position=0, leave=True):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        out = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        loss = criterion(out.permute(1, 2, 0), highlight.permute(1, 0))\n",
    "        total_loss += loss.data.item() * article.size(1)\n",
    "\n",
    "    val_losses.append(total_loss / len(val_dataset))\n",
    "    print(f'epoch {epoch_idx} val loss: {val_losses[-1]}')\n",
    "    writer.add_scalar('Loss/val', val_losses[-1], iter_num)\n",
    "    \n",
    "    indices = sps.randint(0, out.size(1)).rvs(size=3)\n",
    "    pred_texts = tensor_to_text(out[:, indices, :], sp, beam_search=True)\n",
    "    truth_texts = tensor_to_text(highlight[:, indices], sp)\n",
    "    for pred, truth in zip(pred_texts, truth_texts):\n",
    "        print(f'predicted: {pred}')\n",
    "        print(f'truth: {truth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('generator pretraining')\n",
    "plt.plot(np.arange(0, len(epoch_losses)), epoch_losses,\n",
    "         label='train')\n",
    "plt.plot(np.arange(0, len(val_losses)), val_losses,\n",
    "         label='val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'saved_models/pretrained_seq2seq_gen_2.pth'\n",
    "torch.save(G.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. discriminator pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'saved_models/pretrained_seq2seq_gen.pth'\n",
    "G.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (out): Linear(in_features=512, out_features=10000, bias=True)\n",
       "    (w): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (attn_lin): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = 10000\n",
    "padding_idx = 0\n",
    "D = CNNDiscriminator(embed_dim=emb_dim,\n",
    "                     vocab_size=vocab_size,\n",
    "                     num_classes=2,\n",
    "                     filter_sizes=[2, 3, 3],\n",
    "                     num_filters=200,\n",
    "                     padding_idx=padding_idx).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "lr = 0.01\n",
    "opt = torch.optim.Adam(D.parameters(), lr=lr)\n",
    "n_epochs = 1\n",
    "\n",
    "epoch_losses = []\n",
    "val_losses = []\n",
    "iter_num = -1\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [00:34, 15.60it/s]\n",
      "2it [00:00, 17.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss: 0.010462811072112782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:13, 17.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 val loss: 5.129965581755138e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_idx in range(n_epochs):\n",
    "    D.train()\n",
    "    total_loss = 0.\n",
    "    \n",
    "    for batch_idx, data_input in tqdm(enumerate(train_dataloader)):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        generated_highlight = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(generated_highlight, dim=2), dim=2).permute(1, 0)\n",
    "        highlight = highlight.permute(1, 0)\n",
    "        batch = torch.cat([generated_highlight, highlight], dim=0)\n",
    "        targets = torch.tensor([0]*generated_highlight.size(0) + [1]*highlight.size(0)).to(device)\n",
    "        opt.zero_grad()\n",
    "        out = D(batch)\n",
    "        loss = criterion(out.squeeze(1), targets.float())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.data.item() * article.size(1) * 2\n",
    "        iter_num += 1\n",
    "        writer.add_scalar('Loss/train', loss.data.item(), iter_num)\n",
    "    \n",
    "    epoch_losses.append(total_loss / len(train_dataset) / 2)\n",
    "    print(f'epoch {epoch_idx} train loss: {epoch_losses[-1]}')\n",
    "    \n",
    "    D.eval()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, data_input in tqdm(enumerate(val_dataloader)):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        generated_highlight = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(generated_highlight, dim=2), dim=2).permute(1, 0)\n",
    "        highlight = highlight.permute(1, 0)\n",
    "        batch = torch.cat([generated_highlight, highlight], dim=0)\n",
    "        targets = torch.tensor([0]*generated_highlight.size(0) + [1]*highlight.size(0)).to(device)\n",
    "        out = D(batch)\n",
    "        loss = criterion(out.squeeze(1), targets.float())\n",
    "        total_loss += loss.data.item() * article.size(1) * 2\n",
    "\n",
    "    val_losses.append(total_loss / len(val_dataset) / 2)\n",
    "    writer.add_scalar('Loss/val', val_losses[-1], iter_num)\n",
    "    print(f'epoch {epoch_idx} val loss: {val_losses[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('discriminator pretraining')\n",
    "plt.plot(np.arange(0, len(epoch_losses)), epoch_losses,\n",
    "         label='train')\n",
    "plt.plot(np.arange(0, len(val_losses)), val_losses,\n",
    "         label='val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = 'saved_models/pretrained_dis2.pth'\n",
    "# torch.save(D.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "INPUT_DIM = vocab_size\n",
    "OUTPUT_DIM = vocab_size\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 3\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "G = Seq2Seq(enc, dec, device).to(device)\n",
    "save_path = 'saved_models/pretrained_seq2seq_gen.pth'\n",
    "G.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = 10000\n",
    "padding_idx = 0\n",
    "D = CNNDiscriminator(embed_dim=emb_dim,\n",
    "                     vocab_size=vocab_size,\n",
    "                     num_classes=2,\n",
    "                     filter_sizes=[2, 3, 3],\n",
    "                     num_filters=200,\n",
    "                     padding_idx=padding_idx).to(device)\n",
    "save_path = 'saved_models/pretrained_dis2.pth'\n",
    "D.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (out): Linear(in_features=512, out_features=10000, bias=True)\n",
       "    (w): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (attn_lin): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [02:21,  3.80it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 G loss: 62.34072942346092\n",
      "epoch 0 D loss: 0.002295435727957926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:23,  9.89it/s]\n",
      "231it [00:13, 17.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 val loss: 6.240956735741797\n",
      "predicted: uae deports 36 yr old kashmiri over suspected links isis\n",
      "truth: uae deports indian over suspected links with isis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "discriminator_optimizer = torch.optim.Adam(D.parameters(), lr=1e-3)\n",
    "generator_optimizer = torch.optim.Adam(G.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "dis_criterion = nn.BCELoss()\n",
    "\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iter_num = -1\n",
    "G_ce_val_losses = []\n",
    "\n",
    "for epoch_idx in range(n_epochs):\n",
    "    total_G_loss = 0.\n",
    "    total_D_loss = 0.\n",
    "    G.train()\n",
    "    D.train()\n",
    "    for batch_idx, data_input in tqdm(enumerate(train_dataloader)):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        \n",
    "        # Discriminator\n",
    "        generated_highlight = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(generated_highlight, dim=2), dim=2).permute(1, 0)\n",
    "        batch = torch.cat([generated_highlight, highlight.permute(1, 0)], dim=0)\n",
    "        targets = torch.tensor([0]*generated_highlight.size(0) + [1]*highlight.size(1)).to(device)\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        generator_optimizer.zero_grad()\n",
    "        out = D(batch)\n",
    "        loss = dis_criterion(out.squeeze(1), targets.float())\n",
    "        loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "        total_D_loss += loss.data.item() * highlight.size(1) * 2\n",
    "        iter_num += 1\n",
    "        writer.add_scalar('Loss/dis_adv_train', loss.data.item(), iter_num)\n",
    "        \n",
    "        # Generator\n",
    "        generator_optimizer.zero_grad()\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        gen_out = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(gen_out, dim=2), dim=2).permute(1, 0)\n",
    "        rewards = D(generated_highlight).squeeze(1)\n",
    "        rewards = 1 - rewards\n",
    "        pg_loss = G.batch_pgloss(article, highlight, rewards)\n",
    "        pg_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "        writer.add_scalar('Loss/gen_pg_train', pg_loss.data.item(), iter_num)\n",
    "        total_G_loss += pg_loss.data.item() * article.size(1)\n",
    "\n",
    "    G_losses.append(total_G_loss / len(train_dataset))\n",
    "    D_losses.append(total_D_loss / len(train_dataset) / 2)\n",
    "    print(f'epoch {epoch_idx} G loss: {G_losses[-1]}')\n",
    "    print(f'epoch {epoch_idx} D loss: {D_losses[-1]}')\n",
    "    \n",
    "    G.eval()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, data_input in tqdm(enumerate(val_dataloader), position=0, leave=True):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        gen_out = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(gen_out, dim=2), dim=2).permute(1, 0)\n",
    "        rewards = D(generated_highlight).squeeze(1)\n",
    "        rewards = 1 - rewards\n",
    "        pg_loss = G.batch_pgloss(article, highlight, rewards)\n",
    "        total_loss += pg_loss.data.item() * article.size(1)\n",
    "    writer.add_scalar('Loss/gen_pg_val', total_loss / len(val_dataset), iter_num)\n",
    "    \n",
    "    total_loss = 0.\n",
    "    for batch_idx, data_input in tqdm(enumerate(val_dataloader), position=0, leave=True):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        out = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        loss = criterion(out.permute(1, 2, 0), highlight.permute(1, 0))\n",
    "        total_loss += loss.data.item() * article.size(1)\n",
    "\n",
    "    G_ce_val_losses.append(total_loss / len(val_dataset))\n",
    "    print(f'epoch {epoch_idx} val loss: {G_ce_val_losses[-1]}')\n",
    "    writer.add_scalar('Loss/gen_ce_val', G_ce_val_losses[-1], iter_num)\n",
    "    ind = sps.randint(0, out.size(1)).rvs(size=1)[0]\n",
    "    print(f'predicted: {tensor_to_text(out, sp)[ind]}')\n",
    "    print(f'truth: {tensor_to_text(highlight, sp)[ind]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_path = 'saved_models/dis2_adv.pth'\n",
    "#torch.save(D.state_dict(), save_path)\n",
    "\n",
    "#save_path = 'saved_models/gen_adv.pth'\n",
    "#torch.save(G.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
