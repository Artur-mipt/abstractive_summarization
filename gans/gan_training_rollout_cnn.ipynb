{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import nlp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.seq2seq_generator import Seq2Seq, Encoder, Decoder\n",
    "from src.cnn_discriminator import CNNDiscriminator\n",
    "from src.rollout import ROLLOUT\n",
    "from src.utils import *\n",
    "from src.dataset import Dataset, Padder\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.2 s, sys: 611 ms, total: 24.8 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if dataset_name == 'cnn':\n",
    "    train_dataset = nlp.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\")\n",
    "    val_dataset = nlp.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"validation\")\n",
    "    test_dataset = nlp.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test\")\n",
    "    train_articles = [process_str(item['article']) for item in train_dataset]\n",
    "    train_highlights = [process_str(item['highlights']) for item in train_dataset]\n",
    "    val_articles = [process_str(item['article']) for item in val_dataset]\n",
    "    val_highlights = [process_str(item['highlights']) for item in val_dataset]\n",
    "elif dataset_name == 'news':\n",
    "    news = pd.read_csv('data/news_summary.csv')\n",
    "    news.headlines = [process_str(s) for s in news.headlines]\n",
    "    news.text = [process_str(s) for s in news.text]\n",
    "    X_train, X_test = train_test_split(news, test_size=0.3,\n",
    "                                       random_state=42)\n",
    "    train_articles = X_train.text.values\n",
    "    train_highlights = X_train.headlines.values\n",
    "    val_articles = X_test.text.values\n",
    "    val_highlights = X_test.headlines.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66414\n",
      "287113\n"
     ]
    }
   ],
   "source": [
    "indices = []\n",
    "for i in range(len(train_articles)):\n",
    "    if len(train_articles[i]) < 2500:\n",
    "        indices.append(i)\n",
    "print(len(indices))\n",
    "print(len(train_articles))\n",
    "train_articles = list(np.array(train_articles)[indices])\n",
    "train_highlights = list(np.array(train_highlights)[indices])\n",
    "\n",
    "indices = []\n",
    "for i in range(len(val_articles)):\n",
    "    if len(val_articles[i]) < 2500:\n",
    "        indices.append(i)\n",
    "        \n",
    "val_articles = list(np.array(val_articles)[indices])\n",
    "val_highlights = list(np.array(val_highlights)[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. sentencepiece model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 2.62 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if train_new_model:\n",
    "    with open('data/cnn_texts.txt', 'a') as f:\n",
    "        for article in tqdm(train_articles):\n",
    "            f.write(article + '\\n')\n",
    "        for highlight in tqdm(train_highlights):\n",
    "            f.write(highlight + '\\n')\n",
    "        for article in tqdm(val_articles):\n",
    "            f.write(article + '\\n')\n",
    "        for highlight in tqdm(val_highlights):\n",
    "            f.write(highlight + '\\n')\n",
    "            \n",
    "    spm.SentencePieceTrainer.train(input='data/cnn_texts.txt',\n",
    "                                   model_prefix='cnn10k',\n",
    "                                   vocab_size=10000,\n",
    "                                   pad_id=0,\n",
    "                                   bos_id=1,\n",
    "                                   eos_id=2,\n",
    "                                   unk_id=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "sp_modelname = f'sentencepiece_models/cnn{int(vocab_size/1000)}k.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file=sp_modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_dataset = Dataset(train_articles, train_highlights, sp=sp)\n",
    "val_dataset = Dataset(val_articles, val_highlights, sp=sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                              collate_fn=Padder(), shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                            collate_fn=Padder(), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = vocab_size\n",
    "OUTPUT_DIM = vocab_size\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 3\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "G = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = 10000\n",
    "padding_idx = 0\n",
    "D = CNNDiscriminator(embed_dim=emb_dim,\n",
    "                     vocab_size=vocab_size,\n",
    "                     num_classes=2,\n",
    "                     filter_sizes=[2, 3, 3],\n",
    "                     num_filters=200,\n",
    "                     padding_idx=padding_idx).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. generator pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "lr = 1e-4\n",
    "opt = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5)\n",
    "start_teacher_forcing = 0.5\n",
    "teacher_forcing_decay = 0.025\n",
    "n_epochs = 50\n",
    "\n",
    "epoch_losses = []\n",
    "val_losses = []\n",
    "iter_num = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8682it [29:34,  5.53it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "16604it [56:42,  4.88it/s]\n",
      "2it [00:00, 16.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train loss: 6.550945527616668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "907it [01:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 val loss: 6.8607014984122445\n",
      "current lr 0.0001\n",
      "current teacher forcing: 0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: manchester united hasedededed in the in the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "truth: tomasz kucz to spend a week with manchester united on trial poland goalkeeper is wanted by several top clubs after impressing for u15s liverpool rangers and bayer leverkusen have offered the youngster trials fulham and everton are also interested in the 15 year old stopper click here for all the latest manchester united news\n",
      "\n",
      "predicted: manchester united hasededed to the in the in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "truth: manchester city paid the price against burnley admits jesus navas manuel pellegrini s side fellow to 1 0 defeat at turf moor on saturday george boyd scored as city s title chances suffered a serious blow\n",
      "\n",
      "predicted: thesssss the thes in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "truth: 13 month independent investigation into doping in cycling concluded 22 â  page report released by cycling independent reform commission report said doping in cycling has improved but is still going on athletes now have to evade the athlete biological passport system\n",
      "\n",
      "predicted: manchester united hasedededed in the in the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "truth: tomasz kucz to spend a week with manchester united on trial poland goalkeeper is wanted by several top clubs after impressing for u15s liverpool rangers and bayer leverkusen have offered the youngster trials fulham and everton are also interested in the 15 year old stopper click here for all the latest manchester united news\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16604it [56:38,  4.89it/s]\n",
      "2it [00:00, 13.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 train loss: 6.414966688406845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "907it [01:00, 15.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 val loss: 6.786892848871772\n",
      "current lr 0.0001\n",
      "current teacher forcing: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: manchester united hasedededed in the in the the the the the the the theed the the the the the the the the the the the the the the the the the the\n",
      "truth: former newcastle midfielder yohan cabaye will travel to stamford bridge the frenchman has been sidelined with a groin injury since february 14 psg will however be missing winger lucas and defender serge aurier\n",
      "\n",
      "predicted: police say theededededed in the in in the in the the the theed the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "truth: the dog called cabela was shot twice in the neck and once in the shoulder injuries were so severe its front right leg will be amputated in coming days police arrived in sulphur springs area after three calls of shots being fired they are asking for public s help to hunt down culprit and the dog s owner\n",
      "\n",
      "predicted: thesssssssssssssssssssssssssssssssssssssssssssssssssssss\n",
      "truth: woolworths give away the dominoes with every 20 spent in store parents are willing to pay hundreds for full sets for their kids the toys are part of a promotion with disney pixar individual rare dominos are also on sale on ebay\n",
      "\n",
      "predicted: manchester united hasedededed in the in the the the the the the the theed the the the the the the the the the the the the the the the the the the\n",
      "truth: former newcastle midfielder yohan cabaye will travel to stamford bridge the frenchman has been sidelined with a groin injury since february 14 psg will however be missing winger lucas and defender serge aurier\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16604it [56:21,  4.91it/s]\n",
      "2it [00:00, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 train loss: 6.316066002211791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "907it [00:58, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 val loss: 6.725425946804497\n",
      "current lr 0.0001\n",
      "current teacher forcing: 0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: manchester city hasededed to the the for the season the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "truth: alexis sanchez is currently away with chile on international duty chile play iran in st polten on thursday and brazil in london on sunday the arsenal forward has scored 19 goals for the gunners this season click here for all the latest arsenal news\n",
      "\n",
      "predicted: manchester city hasededed to the the for the season the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "truth: alexis sanchez is currently away with chile on international duty chile play iran in st polten on thursday and brazil in london on sunday the arsenal forward has scored 19 goals for the gunners this season click here for all the latest arsenal news\n",
      "\n",
      "predicted: thessed the the in the in the in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "truth: the lion named clara is being fed goat s milk and vitamins zoo keepers are caring for her in her own private quarters the two month old is the first to be born in captivity in brazil keepers plan to reintroduce clara to her pack in four months\n",
      "\n",
      "predicted: the man wasededed a a in a in in a in in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "truth: a man attempted to rob the ok food store in houston texas early thursday morning at gunpoint as soon as the man pulled his gun the store clerk began repeatedly swatting at it the man then fled without firing and drove away from the scene with his accomplices\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16604it [56:57,  4.86it/s]\n",
      "2it [00:00, 14.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 train loss: 6.248036321400555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "907it [00:59, 15.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 val loss: 6.65902082449546\n",
      "current lr 0.0001\n",
      "current teacher forcing: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: the was wasedededed in in in in in he wasedededed in the he waseded to theed to the he waseded to theed to theed to the he waseded to theed to the the he waseded to theed to the\n",
      "truth: killer simon hennessey jailed after 15 years on the run in australia serving life sentence for manslaughter when walked out of open prison 50 year old arrested 15 years later by officers probing credit card fraud hennessey was using stolen identity of man left brain damaged in smash after serving five and a half years in jail in australia deported back to uk judge jails hennessey for a further 16 months for evading lawful custody\n",
      "\n",
      "predicted: the was wasedededed in in in in in he wasedededed in the he waseded to theed to the he waseded to theed to theed to the he waseded to theed to the the he waseded to theed to the\n",
      "truth: killer simon hennessey jailed after 15 years on the run in australia serving life sentence for manslaughter when walked out of open prison 50 year old arrested 15 years later by officers probing credit card fraud hennessey was using stolen identity of man left brain damaged in smash after serving five and a half years in jail in australia deported back to uk judge jails hennessey for a further 16 months for evading lawful custody\n",
      "\n",
      "predicted: the was wasedededed in in in in in he wasedededed in the he waseded to theed to the he waseded to theed to theed to the he waseded to theed to the the he waseded to theed to the\n",
      "truth: killer simon hennessey jailed after 15 years on the run in australia serving life sentence for manslaughter when walked out of open prison 50 year old arrested 15 years later by officers probing credit card fraud hennessey was using stolen identity of man left brain damaged in smash after serving five and a half years in jail in australia deported back to uk judge jails hennessey for a further 16 months for evading lawful custody\n",
      "\n",
      "predicted: floyd mayweather hasededed the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the fight the\n",
      "truth: manny pacquiao fights floyd mayweather at the mgm grand on may 2 filipino has been training at the wild card boxing club in los angeles the 36 year old had previously complained about feeling slow trainer freddie roach insists pacquiao will be performing a public service by beating mayweather\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16604it [56:58,  4.86it/s]\n",
      "2it [00:00, 14.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 train loss: 6.196326683052016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "907it [00:58, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 val loss: 6.617648491654402\n",
      "current lr 0.0001\n",
      "current teacher forcing: 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: theyy was wasededed her in in in in in in hers she waseded hered the her and hered the the the the the the the theed the the the the the the the the the theed the the\n",
      "truth: keyanna rivera went into labor at her doctor s office her doctor dr devalla was a few miles away finishing surgery using app dr devalla was able to help her assistants through the delivery\n",
      "\n",
      "predicted: bayern munich beats 1 0 in the in in in in in the the the the the the the the the in the in the in the the the the the the the the the in the in the in the thes the in the the\n",
      "truth: seven french coaches travelled to bayern munich for three days zinedine zidane joined willy sagnol claude makelele guy lacombe bernard diomede claude le roy and franck thivillier they watched pep guardiola take training of the bundesliga champions\n",
      "\n",
      "predicted: thesssssssssssssssssssssssssssssssssssssss\n",
      "truth: volcano shoots ash into the atmosphere some 30 000 feet winds blow ash cloud across the bering sea and into western alaska\n",
      "\n",
      "predicted: the madrid aresed in the in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "truth: real madrid have ruled out possibility of hosting copa del rey final barcelona want final to be held at valencia s mestalla stadium whereas athletic bilbao believe final should be held in seville\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14437it [49:28,  4.22it/s]"
     ]
    }
   ],
   "source": [
    "for epoch_idx in range(n_epochs):\n",
    "    G.train()\n",
    "    total_loss = 0.\n",
    "    teacher_forcing = start_teacher_forcing - epoch_idx*teacher_forcing_decay\n",
    "    for batch_idx, data_input in tqdm(enumerate(train_dataloader), position=0, leave=True):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        opt.zero_grad()\n",
    "        out = G(article, highlight, teacher_forcing_ratio=teacher_forcing)\n",
    "        loss = criterion(out.permute(1, 2, 0), highlight.permute(1, 0))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.data.item() * article.size(1)\n",
    "        iter_num += 1\n",
    "        if iter_num % 1000 == 0:\n",
    "            writer.add_scalar('Loss/train', loss.data.item(), iter_num)\n",
    "    \n",
    "    epoch_losses.append(total_loss / len(train_dataset))\n",
    "    print(f'epoch {epoch_idx} train loss: {epoch_losses[-1]}')\n",
    "    \n",
    "    G.eval()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, data_input in tqdm(enumerate(val_dataloader), position=0, leave=True):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        out = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        loss = criterion(out.permute(1, 2, 0), highlight.permute(1, 0))\n",
    "        total_loss += loss.data.item() * article.size(1)\n",
    "\n",
    "    val_loss = total_loss / len(val_dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'epoch {epoch_idx} val loss: {val_losses[-1]}')\n",
    "    writer.add_scalar('Loss/val', val_losses[-1], iter_num)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    print(f'current lr {get_lr(opt)}')\n",
    "    print(f'current teacher forcing: {teacher_forcing}')\n",
    "    \n",
    "    indices = sps.randint(0, out.size(1)).rvs(size=4)\n",
    "    pred_texts = tensor_to_text(out[:, indices, :], sp, beam_search=True)\n",
    "    truth_texts = tensor_to_text(highlight[:, indices], sp)\n",
    "    for pred, truth in zip(pred_texts, truth_texts):\n",
    "        print(f'predicted: {pred}')\n",
    "        print(f'truth: {truth}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('generator pretraining')\n",
    "plt.plot(np.arange(0, len(epoch_losses)), epoch_losses,\n",
    "         label='train')\n",
    "plt.plot(np.arange(0, len(val_losses)), val_losses,\n",
    "         label='val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'saved_models/pretrained_seq2seq_gen_4.pth'\n",
    "torch.save(G.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. discriminator pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = 'saved_models/pretrained_seq2seq_gen_3.pth'\n",
    "G.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (out): Linear(in_features=512, out_features=10000, bias=True)\n",
       "    (w): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (attn_lin): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = 10000\n",
    "padding_idx = 0\n",
    "D = CNNDiscriminator(embed_dim=emb_dim,\n",
    "                     vocab_size=vocab_size,\n",
    "                     num_classes=2,\n",
    "                     filter_sizes=[2, 3, 3],\n",
    "                     num_filters=3,\n",
    "                     padding_idx=padding_idx).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "lr = 1e-4\n",
    "opt = torch.optim.Adam(D.parameters(), lr=lr)\n",
    "n_epochs = 2\n",
    "\n",
    "epoch_losses = []\n",
    "val_losses = []\n",
    "iter_num = -1\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [00:44, 12.18it/s]\n",
      "2it [00:00, 14.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss: 0.23779804286710338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:16, 14.16it/s]\n",
      "2it [00:00, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 val loss: 0.031208537723029284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [00:43, 12.32it/s]\n",
      "2it [00:00, 13.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train loss: 0.06076200075888883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:16, 14.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 val loss: 0.005752120049201727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_idx in range(n_epochs):\n",
    "    D.train()\n",
    "    total_loss = 0.\n",
    "    \n",
    "    for batch_idx, data_input in tqdm(enumerate(train_dataloader)):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        generated_highlight = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(generated_highlight, dim=2), dim=2).permute(1, 0)\n",
    "        highlight = highlight.permute(1, 0)\n",
    "        batch = torch.cat([generated_highlight, highlight], dim=0)\n",
    "        targets = torch.tensor([0]*generated_highlight.size(0) + [1]*highlight.size(0)).to(device)\n",
    "        opt.zero_grad()\n",
    "        out = D(batch)\n",
    "        loss = criterion(out.squeeze(1), targets.float())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.data.item() * article.size(1) * 2\n",
    "        iter_num += 1\n",
    "        writer.add_scalar('Loss/train', loss.data.item(), iter_num)\n",
    "    \n",
    "    epoch_losses.append(total_loss / len(train_dataset) / 2)\n",
    "    print(f'epoch {epoch_idx} train loss: {epoch_losses[-1]}')\n",
    "    \n",
    "    D.eval()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, data_input in tqdm(enumerate(val_dataloader)):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        generated_highlight = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(generated_highlight, dim=2), dim=2).permute(1, 0)\n",
    "        highlight = highlight.permute(1, 0)\n",
    "        batch = torch.cat([generated_highlight, highlight], dim=0)\n",
    "        targets = torch.tensor([0]*generated_highlight.size(0) + [1]*highlight.size(0)).to(device)\n",
    "        out = D(batch)\n",
    "        loss = criterion(out.squeeze(1), targets.float())\n",
    "        total_loss += loss.data.item() * article.size(1) * 2\n",
    "\n",
    "    val_losses.append(total_loss / len(val_dataset) / 2)\n",
    "    writer.add_scalar('Loss/val', val_losses[-1], iter_num)\n",
    "    print(f'epoch {epoch_idx} val loss: {val_losses[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('discriminator pretraining')\n",
    "plt.plot(np.arange(0, len(epoch_losses)), epoch_losses,\n",
    "         label='train')\n",
    "plt.plot(np.arange(0, len(val_losses)), val_losses,\n",
    "         label='val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'saved_models/pretrained_dis3.pth'\n",
    "torch.save(D.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "INPUT_DIM = vocab_size\n",
    "OUTPUT_DIM = vocab_size\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 3\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "G = Seq2Seq(enc, dec, device).to(device)\n",
    "save_path = 'saved_models/pretrained_seq2seq_gen_3.pth'\n",
    "G.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = 10000\n",
    "padding_idx = 0\n",
    "D = CNNDiscriminator(embed_dim=emb_dim,\n",
    "                     vocab_size=vocab_size,\n",
    "                     num_classes=2,\n",
    "                     filter_sizes=[2, 3, 3],\n",
    "                     num_filters=3,\n",
    "                     padding_idx=padding_idx).to(device)\n",
    "save_path = 'saved_models/pretrained_dis3.pth'\n",
    "D.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "rollout_num = 2\n",
    "beta = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (out): Linear(in_features=512, out_features=10000, bias=True)\n",
       "    (w): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (attn_lin): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNDiscriminator(\n",
       "  (embed): Embedding(10000, 256, padding_idx=0)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 3, kernel_size=(2, 256), stride=(1, 1))\n",
       "    (1): Conv2d(1, 3, kernel_size=(3, 256), stride=(1, 1))\n",
       "    (2): Conv2d(1, 3, kernel_size=(3, 256), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=9, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "248it [06:51,  1.71s/it]"
     ]
    }
   ],
   "source": [
    "discriminator_optimizer = torch.optim.Adam(D.parameters(), lr=1e-4)\n",
    "generator_optimizer = torch.optim.Adam(G.parameters(), lr=1e-4)\n",
    "criterion_ml = nn.CrossEntropyLoss(ignore_index=0)\n",
    "dis_criterion = nn.BCELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(generator_optimizer, 'min', patience=5)\n",
    "\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iter_num = -1\n",
    "G_ce_val_losses = []\n",
    "\n",
    "for epoch_idx in range(n_epochs):\n",
    "    total_G_loss = 0.\n",
    "    total_D_loss = 0.\n",
    "    G.train()\n",
    "    D.train()\n",
    "    for batch_idx, data_input in tqdm(enumerate(train_dataloader)):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        \n",
    "        # Discriminator\n",
    "        '''\n",
    "        generated_highlight = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(generated_highlight, dim=2), dim=2).permute(1, 0)\n",
    "        batch = torch.cat([generated_highlight, highlight.permute(1, 0)], dim=0)\n",
    "        targets = torch.tensor([0]*generated_highlight.size(0) + [1]*highlight.size(1)).to(device)\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        generator_optimizer.zero_grad()\n",
    "        out = D(batch)\n",
    "        loss = dis_criterion(out.squeeze(1), targets.float())\n",
    "        loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "        total_D_loss += loss.data.item() * highlight.size(1) * 2\n",
    "        iter_num += 1\n",
    "        writer.add_scalar('Loss/dis_adv_train', loss.data.item(), iter_num)\n",
    "        '''\n",
    "        iter_num += 1\n",
    "        \n",
    "        # Generator\n",
    "        generator_optimizer.zero_grad()\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        gen_out = G.sample(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(gen_out, dim=2), dim=2).permute(1, 0)\n",
    "        rollout_func = ROLLOUT(G)\n",
    "        rewards = rollout_func.get_reward(article, generated_highlight, rollout_num, D)\n",
    "        # rewards = 1 - rewards\n",
    "        writer.add_scalar('Reward/train', rewards.mean().data.item(), iter_num)\n",
    "        pg_loss = G.batch_pgloss(article, highlight, rewards)\n",
    "        \n",
    "        out = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        ml_loss = criterion_ml(out.permute(1, 2, 0), highlight.permute(1, 0))\n",
    "        \n",
    "        loss = beta*pg_loss + (1-beta)*ml_loss\n",
    "        loss.backward()\n",
    "        generator_optimizer.step()\n",
    "        writer.add_scalar('Loss_train/loss', loss.data.item(), iter_num)\n",
    "        writer.add_scalar('Loss_train/ml_loss', ml_loss.data.item(), iter_num)\n",
    "        writer.add_scalar('Loss_train/pg_loss', pg_loss.data.item(), iter_num)\n",
    "        total_G_loss += loss.data.item() * article.size(1)\n",
    "\n",
    "    G_losses.append(total_G_loss / len(train_dataset))\n",
    "    D_losses.append(total_D_loss / len(train_dataset) / 2)\n",
    "    print(f'epoch {epoch_idx} G loss: {G_losses[-1]}')\n",
    "    print(f'epoch {epoch_idx} D loss: {D_losses[-1]}')\n",
    "    \n",
    "    G.eval()\n",
    "    total_loss = 0.\n",
    "    total_reward = 0.\n",
    "    total_ml_loss = 0.\n",
    "    total_pg_loss = 0.\n",
    "    for batch_idx, data_input in tqdm(enumerate(val_dataloader), position=0, leave=True):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        gen_out = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(gen_out, dim=2), dim=2).permute(1, 0)\n",
    "        rollout_func = ROLLOUT(G)\n",
    "        rewards = rollout_func.get_reward(article, generated_highlight, rollout_num, D)\n",
    "        # rewards = 1 - rewards\n",
    "        total_reward += rewards.mean().data.item() * article.size(1)\n",
    "        pg_loss = G.batch_pgloss(article, highlight, rewards)\n",
    "        \n",
    "        out = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        ml_loss = criterion_ml(out.permute(1, 2, 0), highlight.permute(1, 0))\n",
    "        \n",
    "        loss = beta*pg_loss + (1-beta)*ml_loss\n",
    "        total_loss += loss.data.item() * article.size(1)\n",
    "        \n",
    "        total_ml_loss += ml_loss.data.item() * article.size(1)\n",
    "        total_pg_loss += pg_loss.data.item() * article.size(1)\n",
    "    writer.add_scalar('Reward/val', total_reward / len(val_dataset), iter_num)\n",
    "    writer.add_scalar('Loss_val/loss', total_loss / len(val_dataset), iter_num)\n",
    "    writer.add_scalar('Loss_val/ml_loss', total_ml_loss / len(val_dataset), iter_num)\n",
    "    writer.add_scalar('Loss_val/pg_loss', total_pg_loss / len(val_dataset), iter_num)\n",
    "    \n",
    "    scheduler.step(total_loss)\n",
    "    \n",
    "    G_ce_val_losses.append(total_loss / len(val_dataset))\n",
    "    print(f'epoch {epoch_idx} val loss: {G_ce_val_losses[-1]}')\n",
    "    # writer.add_scalar('Loss/gen_ce_val', G_ce_val_losses[-1], iter_num)\n",
    "    \n",
    "    indices = sps.randint(0, out.size(1)).rvs(size=10)\n",
    "    pred_texts = tensor_to_text(out[:, indices, :], sp, beam_search=True)\n",
    "    truth_texts = tensor_to_text(highlight[:, indices], sp)\n",
    "    for pred, truth in zip(pred_texts, truth_texts):\n",
    "        print(f'predicted: {pred}')\n",
    "        print(f'truth: {truth}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'saved_models/dis4_adv.pth'\n",
    "torch.save(D.state_dict(), save_path)\n",
    "\n",
    "save_path = 'saved_models/gen4_adv.pth'\n",
    "torch.save(G.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
