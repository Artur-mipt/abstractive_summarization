{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as sps\n",
    "import nlp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.seq2seq_generator import Seq2Seq, Encoder, Decoder\n",
    "from src.cnn_discriminator import CNNDiscriminator\n",
    "from src.rollout import ROLLOUT\n",
    "from src.utils import *\n",
    "from src.dataset import Dataset, Padder\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 745 ms, sys: 23.9 ms, total: 769 ms\n",
      "Wall time: 768 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if dataset_name == 'cnn':\n",
    "    train_dataset = nlp.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train\")\n",
    "    val_dataset = nlp.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"validation\")\n",
    "    test_dataset = nlp.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test\")\n",
    "    train_articles = [item['article'] for item in train_dataset]\n",
    "    train_highlights = [item['highlights'] for item in train_dataset]\n",
    "    val_articles = [item['article'] for item in val_dataset]\n",
    "    val_highlights = [item['highlights'] for item in val_dataset]\n",
    "elif dataset_name == 'news':\n",
    "    news = pd.read_csv('data/news_summary.csv')\n",
    "    news.headlines = [process_str(s) for s in news.headlines]\n",
    "    news.text = [process_str(s) for s in news.text]\n",
    "    X_train, X_test = train_test_split(news, test_size=0.3,\n",
    "                                       random_state=42)\n",
    "    train_articles = X_train.text.values\n",
    "    train_highlights = X_train.headlines.values\n",
    "    val_articles = X_test.text.values\n",
    "    val_highlights = X_test.headlines.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. sentencepiece model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if train_new_model:\n",
    "    with open('data/news_texts.txt', 'a') as f:\n",
    "        for article in tqdm(train_articles):\n",
    "            f.write(article + '\\n')\n",
    "        for highlight in tqdm(train_highlights):\n",
    "            f.write(highlight + '\\n')\n",
    "        for article in tqdm(val_articles):\n",
    "            f.write(article + '\\n')\n",
    "        for highlight in tqdm(val_highlights):\n",
    "            f.write(highlight + '\\n')\n",
    "            \n",
    "    spm.SentencePieceTrainer.train(input='data/news_texts.txt',\n",
    "                                   model_prefix='news10k',\n",
    "                                   vocab_size=10000,\n",
    "                                   pad_id=0,\n",
    "                                   bos_id=1,\n",
    "                                   eos_id=2,\n",
    "                                   unk_id=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "sp_modelname = f'sentencepiece_models/news{int(vocab_size/1000)}k.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file=sp_modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_articles, train_highlights, sp=sp)\n",
    "val_dataset = Dataset(val_articles, val_highlights, sp=sp)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128,\n",
    "                              collate_fn=Padder(), shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128,\n",
    "                            collate_fn=Padder(), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([102, 128])\n",
      "torch.Size([24, 128])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch[0].size())\n",
    "    print(batch[1].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = vocab_size\n",
    "OUTPUT_DIM = vocab_size\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 3\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "G = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = 10000\n",
    "padding_idx = 0\n",
    "D = CNNDiscriminator(embed_dim=emb_dim,\n",
    "                     vocab_size=vocab_size,\n",
    "                     num_classes=2,\n",
    "                     filter_sizes=[2, 3, 3],\n",
    "                     num_filters=200,\n",
    "                     padding_idx=padding_idx).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. generator pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "lr = 1e-3\n",
    "opt = torch.optim.Adam(G.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'min', patience=5)\n",
    "start_teacher_forcing = 0.5\n",
    "teacher_forcing_decay = 0.025\n",
    "n_epochs = 50\n",
    "\n",
    "epoch_losses = []\n",
    "val_losses = []\n",
    "iter_num = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:03,  6.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-16dba62ccf83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher_forcing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/texts37/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/texts37/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch_idx in range(n_epochs):\n",
    "    G.train()\n",
    "    total_loss = 0.\n",
    "    teacher_forcing = start_teacher_forcing - epoch_idx*teacher_forcing_decay\n",
    "    for batch_idx, data_input in tqdm(enumerate(train_dataloader), position=0, leave=True):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        opt.zero_grad()\n",
    "        out = G(article, highlight, teacher_forcing_ratio=teacher_forcing)\n",
    "        loss = criterion(out.permute(1, 2, 0), highlight.permute(1, 0))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.data.item() * article.size(1)\n",
    "        iter_num += 1\n",
    "        writer.add_scalar('Loss/train', loss.data.item(), iter_num)\n",
    "    \n",
    "    epoch_losses.append(total_loss / len(train_dataset))\n",
    "    print(f'epoch {epoch_idx} train loss: {epoch_losses[-1]}')\n",
    "    \n",
    "    G.eval()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, data_input in tqdm(enumerate(val_dataloader), position=0, leave=True):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        out = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        loss = criterion(out.permute(1, 2, 0), highlight.permute(1, 0))\n",
    "        total_loss += loss.data.item() * article.size(1)\n",
    "\n",
    "    val_loss = total_loss / len(val_dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f'epoch {epoch_idx} val loss: {val_losses[-1]}')\n",
    "    writer.add_scalar('Loss/val', val_losses[-1], iter_num)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    print(f'current lr {get_lr(opt)}')\n",
    "    print(f'current teacher forcing: {teacher_forcing}')\n",
    "    \n",
    "    indices = sps.randint(0, out.size(1)).rvs(size=5)\n",
    "    pred_texts = tensor_to_text(out[:, indices, :], sp, beam_search=True)\n",
    "    truth_texts = tensor_to_text(highlight[:, indices], sp)\n",
    "    for pred, truth in zip(pred_texts, truth_texts):\n",
    "        print(f'predicted: {pred}')\n",
    "        print(f'truth: {truth}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('generator pretraining')\n",
    "plt.plot(np.arange(0, len(epoch_losses)), epoch_losses,\n",
    "         label='train')\n",
    "plt.plot(np.arange(0, len(val_losses)), val_losses,\n",
    "         label='val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = 'saved_models/pretrained_seq2seq_gen_3.pth'\n",
    "# torch.save(G.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. discriminator pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = 'saved_models/pretrained_seq2seq_gen.pth'\n",
    "G.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (out): Linear(in_features=512, out_features=10000, bias=True)\n",
       "    (w): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (attn_lin): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = 10000\n",
    "padding_idx = 0\n",
    "D = CNNDiscriminator(embed_dim=emb_dim,\n",
    "                     vocab_size=vocab_size,\n",
    "                     num_classes=2,\n",
    "                     filter_sizes=[2, 3, 3],\n",
    "                     num_filters=3,\n",
    "                     padding_idx=padding_idx).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "lr = 1e-4\n",
    "opt = torch.optim.Adam(D.parameters(), lr=lr)\n",
    "n_epochs = 2\n",
    "\n",
    "epoch_losses = []\n",
    "val_losses = []\n",
    "iter_num = -1\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [00:43, 12.46it/s]\n",
      "2it [00:00, 14.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss: 0.3928120992947954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:15, 14.44it/s]\n",
      "2it [00:00, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 val loss: 0.10172562454329778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [00:43, 12.45it/s]\n",
      "2it [00:00, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train loss: 0.1146431076298192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [00:15, 14.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 val loss: 0.021911663011058163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_idx in range(n_epochs):\n",
    "    D.train()\n",
    "    total_loss = 0.\n",
    "    \n",
    "    for batch_idx, data_input in tqdm(enumerate(train_dataloader)):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        generated_highlight = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(generated_highlight, dim=2), dim=2).permute(1, 0)\n",
    "        highlight = highlight.permute(1, 0)\n",
    "        batch = torch.cat([generated_highlight, highlight], dim=0)\n",
    "        targets = torch.tensor([0]*generated_highlight.size(0) + [1]*highlight.size(0)).to(device)\n",
    "        opt.zero_grad()\n",
    "        out = D(batch)\n",
    "        loss = criterion(out.squeeze(1), targets.float())\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total_loss += loss.data.item() * article.size(1) * 2\n",
    "        iter_num += 1\n",
    "        writer.add_scalar('Loss/train', loss.data.item(), iter_num)\n",
    "    \n",
    "    epoch_losses.append(total_loss / len(train_dataset) / 2)\n",
    "    print(f'epoch {epoch_idx} train loss: {epoch_losses[-1]}')\n",
    "    \n",
    "    D.eval()\n",
    "    total_loss = 0.\n",
    "    for batch_idx, data_input in tqdm(enumerate(val_dataloader)):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        generated_highlight = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = torch.argmax(F.softmax(generated_highlight, dim=2), dim=2).permute(1, 0)\n",
    "        highlight = highlight.permute(1, 0)\n",
    "        batch = torch.cat([generated_highlight, highlight], dim=0)\n",
    "        targets = torch.tensor([0]*generated_highlight.size(0) + [1]*highlight.size(0)).to(device)\n",
    "        out = D(batch)\n",
    "        loss = criterion(out.squeeze(1), targets.float())\n",
    "        total_loss += loss.data.item() * article.size(1) * 2\n",
    "\n",
    "    val_losses.append(total_loss / len(val_dataset) / 2)\n",
    "    writer.add_scalar('Loss/val', val_losses[-1], iter_num)\n",
    "    print(f'epoch {epoch_idx} val loss: {val_losses[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('discriminator pretraining')\n",
    "plt.plot(np.arange(0, len(epoch_losses)), epoch_losses,\n",
    "         label='train')\n",
    "plt.plot(np.arange(0, len(val_losses)), val_losses,\n",
    "         label='val')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'saved_models/pretrained_dis3.pth'\n",
    "torch.save(D.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "INPUT_DIM = vocab_size\n",
    "OUTPUT_DIM = vocab_size\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 3\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "G = Seq2Seq(enc, dec, device).to(device)\n",
    "save_path = 'saved_models/pretrained_seq2seq_gen_3.pth'\n",
    "G.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = 10000\n",
    "padding_idx = 0\n",
    "D = CNNDiscriminator(embed_dim=emb_dim,\n",
    "                     vocab_size=vocab_size,\n",
    "                     num_classes=2,\n",
    "                     filter_sizes=[2, 3, 3],\n",
    "                     num_filters=3,\n",
    "                     padding_idx=padding_idx).to(device)\n",
    "save_path = 'saved_models/pretrained_dis3.pth'\n",
    "D.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 60\n",
    "rollout_num = 2\n",
    "beta = 0.2\n",
    "teacher_forcing = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(10000, 256)\n",
       "    (rnn): LSTM(256, 256, num_layers=3, dropout=0.1)\n",
       "    (out): Linear(in_features=512, out_features=10000, bias=True)\n",
       "    (w): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (attn_lin): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNDiscriminator(\n",
       "  (embed): Embedding(10000, 256, padding_idx=0)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 3, kernel_size=(2, 256), stride=(1, 1))\n",
       "    (1): Conv2d(1, 3, kernel_size=(3, 256), stride=(1, 1))\n",
       "    (2): Conv2d(1, 3, kernel_size=(3, 256), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1): Linear(in_features=9, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:20,  1.71s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 G loss: 3.0428482192457067\n",
      "epoch 0 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:49,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 val loss: 5.598559960969753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: airbus probe probe probe corruption charges insexexexex\n",
      "truth: airbus launches internal corruption investigation\n",
      "\n",
      "predicted: french singer ss dies after collapsing in in\n",
      "truth: french singer barbara weldens dies on stage during concert\n",
      "\n",
      "predicted: airbus probe probe probe corruption charges insexexexex\n",
      "truth: airbus launches internal corruption investigation\n",
      "\n",
      "predicted: pm pm pm pm pm sssnanana s resigns\n",
      "truth: georgia pm kvirikashvili resigns amid rift with ruling party\n",
      "\n",
      "predicted: daughters should t t  good good touch touch mp cm\n",
      "truth: daughters should be taught about good bad touch mp cm\n",
      "\n",
      "predicted: kejriwal kejriwal kejriwal defamation defamation case against delhi\n",
      "truth: delhi cm discharged in defamation case over thulla remark\n",
      "\n",
      "predicted: us man awarded 4 4 crore after eating burntopopusus\n",
      "truth: us man awarded 4 8 crore after beer burns his organs\n",
      "\n",
      "predicted: barcelona 1st club club to earn over 44 bn in\n",
      "truth: barcelona become world s 1st team to spend 500 million on wages\n",
      "\n",
      "predicted: demonetismohan speecheded butededed minister minister\n",
      "truth: manmohan s speech on demonetisation was scripted prasad\n",
      "\n",
      "predicted: 23 year billionaire billionairess hurun s since this year\n",
      "truth: 27 hurun rich list billionaires passed away last year\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:35,  1.74s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 G loss: 2.8284000407804872\n",
      "epoch 1 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:50,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 val loss: 5.575447749519755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: airbus probe probe into corruption charges insexexexex\n",
      "truth: airbus launches internal corruption investigation\n",
      "\n",
      "predicted: my child sawenenclaimsss s abd to kid\n",
      "truth: de villiers hid love letters he wrote in his house s roof\n",
      "\n",
      "predicted: b luru police challenges challenge onoutoutoutout pic\n",
      "truth: b luru police ask people to wear helmets share 10 secs challenge\n",
      "\n",
      "predicted: nasa propose proposes using co comicmicmics glass\n",
      "truth: nasa team proposes using sun as cosmic magnifying glass\n",
      "\n",
      "predicted: nasa probess of 1 lakh lakh indians on a chip\n",
      "truth: nasa spacecraft landed on mars with names of over 1l indians\n",
      "\n",
      "predicted: nation will become asian pure under imran imran khan\n",
      "truth: pak will become asian tiger under imran khan shoaib akhtar\n",
      "\n",
      "predicted: 35 men married married atpointpoint in bihar 2016\n",
      "truth: 3 075 grooms got married in bihar at gunpoint in 2016\n",
      "\n",
      "predicted: amazon should pay real money real money taxes donald trump\n",
      "truth: amazon must pay real costs and taxes now donald trump\n",
      "\n",
      "predicted: whatsapp should have a new news union minister ceo\n",
      "truth: whatsapp must have grievance officer in india it min to ceo\n",
      "\n",
      "predicted: aus cricket venuesed to bengaluru s b luru traffic\n",
      "truth: match s pre lunch session extended as food stuck in b luru traffic\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:35,  1.73s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 G loss: 2.7974252279904106\n",
      "epoch 2 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:50,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 val loss: 5.452959704296541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: gotaradhya for the from my my actor on on 13 years\n",
      "truth: received best compliment from dilip kumar for black big b\n",
      "\n",
      "predicted: ddkock rules out of ipl ipl match to to match\n",
      "truth: delhi s last year top scorer quinton de kock out of ipl 2017\n",
      "\n",
      "predicted: pak ak ak player as ased from trophy trophyninini\n",
      "truth: akmal should be ashamed for being sent back to pak waqar\n",
      "\n",
      "predicted: french singer ss dies after collapsing in concert\n",
      "truth: french singer barbara weldens dies on stage during concert\n",
      "\n",
      "predicted: astronomers helped wavesed earth 96 years ago study\n",
      "truth: online volunteers help find star that exploded 97 cr yrs ago\n",
      "\n",
      "predicted: astronomers helped wavesed earth 96 years ago study\n",
      "truth: online volunteers help find star that exploded 97 cr yrs ago\n",
      "\n",
      "predicted: 4 missiles fired from afghanistan in pakistan\n",
      "truth: 4 missiles fired into pakistan from afghanistan\n",
      "\n",
      "predicted: srikanthambi srikanth conferred padma shri\n",
      "truth: kidambi srikanth conferred with padma shri award\n",
      "\n",
      "predicted: astronomers helped wavesed earth 96 years ago study\n",
      "truth: online volunteers help find star that exploded 97 cr yrs ago\n",
      "\n",
      "predicted: barcelona 1st club to world world record over 126ss\n",
      "truth: barcelona become world s 1st team to spend 500 million on wages\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:36,  1.74s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 G loss: 2.7772496618321827\n",
      "epoch 3 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:49,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 val loss: 5.287601828853765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: i suffering for a mistake conductor conductor conductor driver driver driver driver\n",
      "truth: suffering for no fault driver who let langur control steering\n",
      "\n",
      "predicted: ferrari s f driver driver crashes car car car pr1 car\n",
      "truth: f1 driver crashes after race ends rides back on another car\n",
      "\n",
      "predicted: amazon to test 1 hr for items in fashion show show show\n",
      "truth: amazon to test one hour delivery for fashion show clothes\n",
      "\n",
      "predicted: world s smallest computers made neuros\n",
      "truth: how does the world s smallest computer work\n",
      "\n",
      "predicted: 2015 shooters married married atpoint in bihar 2016\n",
      "truth: 3 075 grooms got married in bihar at gunpoint in 2016\n",
      "\n",
      "predicted: cbi of witch hunting in evidence of sarushia\n",
      "truth: cbi planted witnesses in aarushi murder case allahabad hc\n",
      "\n",
      "predicted: us man awarded 4 8 8 after eating corpses\n",
      "truth: us man awarded 4 8 crore after beer burns his organs\n",
      "\n",
      "predicted: sachin attend attend b day s b m ambani vikram ambani\n",
      "truth: sachin tendulkar attends krunal pandya s wedding in mumbai\n",
      "\n",
      "predicted: wheelchair bound passengers to board flights flight flight\n",
      "truth: air india refuses to let wheelchair bound passenger on plane\n",
      "\n",
      "predicted: us man awarded 4 8 8 after eating corpses\n",
      "truth: us man awarded 4 8 crore after beer burns his organs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:35,  1.74s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 G loss: 2.7639627619487483\n",
      "epoch 4 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:50,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 val loss: 5.076564761601443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: nation will become asian pure under imran imran khan\n",
      "truth: pak will become asian tiger under imran khan shoaib akhtar\n",
      "\n",
      "predicted: cannot be run by byss sports sports sports min\n",
      "truth: sports can t be run by bureaucrats sports minister rathore\n",
      "\n",
      "predicted: vajpayee was firstst to a speech in the from the nation\n",
      "truth: late pm vajpayee was 1st person to give hindi speech at un\n",
      "\n",
      "predicted: kerala govting sabarimalasssssssss shah\n",
      "truth: kerala treating sabarimala pilgrims like gulag inmates shah\n",
      "\n",
      "predicted: aus australia is is good good good good aus coachlanger\n",
      "truth: sledging is a fun part of the game aus coach justin langer\n",
      "\n",
      "predicted: mumbai was 1st first teacher teacher teacher in child child\n",
      "truth: who was savitribai phule india s first female teacher\n",
      "\n",
      "predicted: death toll in gorkhaland strike killed in gorkhaland\n",
      "truth: gorkhaland supporter killed in police firing in darjeeling\n",
      "\n",
      "predicted: rhea s sister  sister s 1st at cannes festival fest\n",
      "truth: sonam wears custom made jewellery by sister rhea at cannes\n",
      "\n",
      "predicted: cong congress joins for for for for poll\n",
      "truth: cong ncp join hands against bjp for maha council by poll\n",
      "\n",
      "predicted: 14 yr old killss after watch watch watch video video at mumbai\n",
      "truth: scolded for using phone mumbai teen hangs self dies in hospital\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:24,  1.72s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 G loss: 2.755716007844081\n",
      "epoch 5 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:40,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 val loss: 4.844102089831727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: sehwag moreinging sehwag oninginging pad pad\n",
      "truth: aus ke score par laga gst bhaari pad gaya sehwag on india s loss\n",
      "\n",
      "predicted: death toll in gorkhaland strike killed in gorkhaland\n",
      "truth: gorkhaland supporter killed in police firing in darjeeling\n",
      "\n",
      "predicted: he have death under undereacheacheacheachss owaisi owaisi\n",
      "truth: threat to my life claims aimim leader akbaruddin owaisi\n",
      "\n",
      "predicted: mccullum scores test test fastest fastest in his last last last\n",
      "truth: brendon mccullum hit test cricket s fastest ton in his last match\n",
      "\n",
      "predicted: un evidence of evidence of human rights rights attack\n",
      "truth: enough evidence to convict syrian prez of war crimes un\n",
      "\n",
      "predicted: demonetismohan waseded butededed minister minister\n",
      "truth: manmohan s speech on demonetisation was scripted prasad\n",
      "\n",
      "predicted: amazon to test 1 hr for for items show show show show\n",
      "truth: amazon to test one hour delivery for fashion show clothes\n",
      "\n",
      "predicted: kerala govting sabarimalasssssssss shah\n",
      "truth: kerala treating sabarimala pilgrims like gulag inmates shah\n",
      "\n",
      "predicted: b luru policess challenge onoutoutoutout\n",
      "truth: b luru police ask people to wear helmets share 10 secs challenge\n",
      "\n",
      "predicted: astronomers helped wavesed earth years ago study\n",
      "truth: online volunteers help find star that exploded 97 cr yrs ago\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:13,  1.70s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 G loss: 2.738384617385687\n",
      "epoch 6 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:40,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 val loss: 4.578166625052383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: keralas make plastic freess for for for marriage\n",
      "truth: village issues marriage certificate only after green wedding\n",
      "\n",
      "predicted: man dies after rid dies dies dies in tripping into car\n",
      "truth: man dies after crashing his scooter into zareen khan s car in goa\n",
      "\n",
      "predicted: nasa probe probes of lakh lakh 38 lakhs on on a\n",
      "truth: nasa spacecraft landed on mars with names of over 1l indians\n",
      "\n",
      "predicted: barable to be against soldiers armyss army army army\n",
      "truth: soldiers to face action for disrespecting militants bodies\n",
      "\n",
      "predicted: first look poster of sushant kriti starrer raabta unveiled\n",
      "truth: first look poster of sushant kriti s raabta unveiled\n",
      "\n",
      "predicted: india smell noting blood buty would be under great coach coach\n",
      "truth: india are smelling blood we will show them great respect langer\n",
      "\n",
      "predicted: kejriwal kejriwal kejriwal defamation defamation casestst police\n",
      "truth: delhi cm discharged in defamation case over thulla remark\n",
      "\n",
      "predicted: sehwag moreinginging sehwag on pad pad pad s wins\n",
      "truth: aus ke score par laga gst bhaari pad gaya sehwag on india s loss\n",
      "\n",
      "predicted: sehwag moreinginging sehwag on pad pad pad s wins\n",
      "truth: aus ke score par laga gst bhaari pad gaya sehwag on india s loss\n",
      "\n",
      "predicted: woman womans after after being liting of in in\n",
      "truth: us woman severely injured after mistaking dynamite for candle\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:15,  1.70s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 G loss: 2.680413704383664\n",
      "epoch 7 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:40,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 val loss: 4.300981256867411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: social media mediasenenenss trump trump trump\n",
      "truth: social media giants are silencing millions of people trump\n",
      "\n",
      "predicted: vajpayee was firstst to speech speech in in  \n",
      "truth: late pm vajpayee was 1st person to give hindi speech at un\n",
      "\n",
      "predicted: nasa propose proposess co comicmicmicmicing glass\n",
      "truth: nasa team proposes using sun as cosmic magnifying glass\n",
      "\n",
      "predicted: barable to be against soldiers armyss army army army\n",
      "truth: soldiers to face action for disrespecting militants bodies\n",
      "\n",
      "predicted: wheelchair passengerseded to flight flight flight flight flight flight\n",
      "truth: air india refuses to let wheelchair bound passenger on plane\n",
      "\n",
      "predicted: man buildssable  in in car water the the\n",
      "truth: man turns his car into a drivable hot tub\n",
      "\n",
      "predicted: barcelona 1s 1st in world to ins\n",
      "truth: barcelona become world s 1st team to spend 500 million on wages\n",
      "\n",
      "predicted: 23 billionaire billionairesst hurunsss\n",
      "truth: 27 hurun rich list billionaires passed away last year\n",
      "\n",
      "predicted: iit roorkee tests floating electricit electricit from water water water\n",
      "truth: iit roorkee tests device to generate electricity from river flow\n",
      "\n",
      "predicted: vajpayee was firstst to speech speech in in  \n",
      "truth: late pm vajpayee was 1st person to give hindi speech at un\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:15,  1.70s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 G loss: 2.5365488761254995\n",
      "epoch 8 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:39,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 val loss: 4.0406626625955235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: zo winds put women at at foree g gnt\n",
      "truth: game of thrones puts women at the forefront gwendoline\n",
      "\n",
      "predicted: demonetismohan wasedededededed minister minister\n",
      "truth: manmohan s speech on demonetisation was scripted prasad\n",
      "\n",
      "predicted: sehwag moreinginging sehwag pad pad pad pad ss\n",
      "truth: aus ke score par laga gst bhaari pad gaya sehwag on india s loss\n",
      "\n",
      "predicted: union union minister minister minister swor swor in in bihar of\n",
      "truth: satya pal malik sworn in as governor of bihar\n",
      "\n",
      "predicted: amazon to test 1 hr for for itemsnn show show show\n",
      "truth: amazon to test one hour delivery for fashion show clothes\n",
      "\n",
      "predicted: ferrari s driver driver car car car car car car pr pr car car\n",
      "truth: f1 driver crashes after race ends rides back on another car\n",
      "\n",
      "predicted: nation will become pure pure under imran imran khan akhtar\n",
      "truth: pak will become asian tiger under imran khan shoaib akhtar\n",
      "\n",
      "predicted: nation will become pure pure under imran imran khan akhtar\n",
      "truth: pak will become asian tiger under imran khan shoaib akhtar\n",
      "\n",
      "predicted: amazon should pay real realss taxess donald trump\n",
      "truth: amazon must pay real costs and taxes now donald trump\n",
      "\n",
      "predicted: kartarpur corridor call callpur for for for for modi modi\n",
      "truth: kartarpur corridor atonement for mistake made in 1947 pm modi\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:10,  1.69s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 G loss: 2.503578015846935\n",
      "epoch 9 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:38,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 val loss: 3.9974233313412175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: pm pm pm pm pm pmsnanananana\n",
      "truth: georgia pm kvirikashvili resigns amid rift with ruling party\n",
      "\n",
      "predicted: never think about what i have have ve ining in kajol kajol\n",
      "truth: i never think about what i should ve done differently kajol\n",
      "\n",
      "predicted: australian australia is is good good good good goodlangerlangerlanger\n",
      "truth: sledging is a fun part of the game aus coach justin langer\n",
      "\n",
      "predicted: pm pm pm pm pm pmsnanananana\n",
      "truth: georgia pm kvirikashvili resigns amid rift with ruling party\n",
      "\n",
      "predicted: nurse whos for foringingingmemese to baby\n",
      "truth: italian nurse jailed for calming newborn with morphine\n",
      "\n",
      "predicted: barable to be against soldiers army armys army army army\n",
      "truth: soldiers to face action for disrespecting militants bodies\n",
      "\n",
      "predicted: d dekockkock rule out out ipl ipl ipl 10 to touch\n",
      "truth: delhi s last year top scorer quinton de kock out of ipl 2017\n",
      "\n",
      "predicted: 4 missiles firededfrom in in pakistan\n",
      "truth: 4 missiles fired into pakistan from afghanistan\n",
      "\n",
      "predicted: farmer farmersinging dump dumpsss strike strike strike strike\n",
      "truth: farmers dump vegetables spill milk on roads during protest\n",
      "\n",
      "predicted: govt issues notice notice rahul rahul foringing for foring\n",
      "truth: rahul given notice over nude dalit kids being beaten up video\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:09,  1.69s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 G loss: 2.495829873301011\n",
      "epoch 10 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:40,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 val loss: 3.9946214878067674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: big b aishwarya bs document document documentss panama panama\n",
      "truth: amitabh aishwarya submit documents in panama papers probe\n",
      "\n",
      "predicted: never think about what i have have ve ininging kajol kajol\n",
      "truth: i never think about what i should ve done differently kajol\n",
      "\n",
      "predicted: aus australiaing is good good good good good auslangerlanger\n",
      "truth: sledging is a fun part of the game aus coach justin langer\n",
      "\n",
      "predicted: thousands can walk walk walk walk on attack attack attack attack\n",
      "truth: event guests sing you ll never walk alone over terror threat\n",
      "\n",
      "predicted: 14 yr old killssing watch watch watch video video\n",
      "truth: scolded for using phone mumbai teen hangs self dies in hospital\n",
      "\n",
      "predicted: i suffering for for a conductor conductor conductor conductor conductor driver driver driver\n",
      "truth: suffering for no fault driver who let langur control steering\n",
      "\n",
      "predicted: world s smallest computer computers neuros\n",
      "truth: how does the world s smallest computer work\n",
      "\n",
      "predicted: airbus launche probe probe probe corruptionssexexex\n",
      "truth: airbus launches internal corruption investigation\n",
      "\n",
      "predicted: google using its s ai ai ai ai chipsroidroid\n",
      "truth: google using ai to improve battery life on android phones\n",
      "\n",
      "predicted: spice ak ak to ashamededed    s\n",
      "truth: akmal should be ashamed for being sent back to pak waqar\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:09,  1.69s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 G loss: 2.4841569462442785\n",
      "epoch 11 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:41,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 val loss: 4.000340101886161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: vajpayee was firstst to speech speech in in  \n",
      "truth: late pm vajpayee was 1st person to give hindi speech at un\n",
      "\n",
      "predicted: thiev thievesss transparent inside house housenn in\n",
      "truth: us thieves try to steal tv return it as it didn t fit in car\n",
      "\n",
      "predicted: social media mediasenenensss trump trump\n",
      "truth: social media giants are silencing millions of people trump\n",
      "\n",
      "predicted: 18 cpi mss life life lifeed  tmc tmc\n",
      "truth: 18 cpi m men get life term for killing tmc workers in 2010\n",
      "\n",
      "predicted: pm modi to visit china in first week summit summit summit summit\n",
      "truth: pm modi to attend brics summit in china\n",
      "\n",
      "predicted: barcelona 1s club world world to overss\n",
      "truth: barcelona become world s 1st team to spend 500 million on wages\n",
      "\n",
      "predicted: gotara award for for   my on d on on year\n",
      "truth: received best compliment from dilip kumar for black big b\n",
      "\n",
      "predicted: b luru policess challenge challenge onoutoutout\n",
      "truth: b luru police ask people to wear helmets share 10 secs challenge\n",
      "\n",
      "predicted: daughter daughter should should t  good good touch touch touch cm cm cm\n",
      "truth: daughters should be taught about good bad touch mp cm\n",
      "\n",
      "predicted: nurse whos for foringingingmemese to\n",
      "truth: italian nurse jailed for calming newborn with morphine\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [15:11,  1.69s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 G loss: 2.4763718682576\n",
      "epoch 12 D loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [04:41,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 val loss: 4.001048757642198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: kerala govtingsssssssssss shah\n",
      "truth: kerala treating sabarimala pilgrims like gulag inmates shah\n",
      "\n",
      "predicted: i would like work with any any actor dutt dutt dutt dutt dutt\n",
      "truth: would like to work with ranbir kapoor again rajkumar hirani\n",
      "\n",
      "predicted: he am death every undereacheacheacheachs owaisi owaisi\n",
      "truth: threat to my life claims aimim leader akbaruddin owaisi\n",
      "\n",
      "predicted: wased to to to to in school school schools rape rape\n",
      "truth: was threatened to change asaram rape victim s age principal\n",
      "\n",
      "predicted: pm modi to visit china in first week summit summit summit summit\n",
      "truth: pm modi to attend brics summit in china\n",
      "\n",
      "predicted: thousands can walk walk walk walk on attack attack attack attack\n",
      "truth: event guests sing you ll never walk alone over terror threat\n",
      "\n",
      "predicted: india smell noting blood wey would be under great coach coach\n",
      "truth: india are smelling blood we will show them great respect langer\n",
      "\n",
      "predicted: nasa probe probes of lakh lakh 38 lakhs on on\n",
      "truth: nasa spacecraft landed on mars with names of over 1l indians\n",
      "\n",
      "predicted: mumbai was 1st first teacher teacher teacher in child child child\n",
      "truth: who was savitribai phule india s first female teacher\n",
      "\n",
      "predicted: maha issue issue notice notice rahul rahul foringing forss\n",
      "truth: rahul given notice over nude dalit kids being beaten up video\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "383it [10:47,  1.72s/it]"
     ]
    }
   ],
   "source": [
    "discriminator_optimizer = torch.optim.Adam(D.parameters(), lr=1e-4)\n",
    "generator_optimizer = torch.optim.Adam(G.parameters(), lr=1e-4)\n",
    "criterion_ml = nn.CrossEntropyLoss(ignore_index=0)\n",
    "dis_criterion = nn.BCELoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(generator_optimizer, 'min', patience=5)\n",
    "\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iter_num = -1\n",
    "G_ce_val_losses = []\n",
    "\n",
    "for epoch_idx in range(n_epochs):\n",
    "    total_G_loss = 0.\n",
    "    total_D_loss = 0.\n",
    "    G.train()\n",
    "    D.train()\n",
    "    beta += 0.02 * epoch_idx\n",
    "    beta = min(0.95, beta)\n",
    "    teacher_forcing -= 0.02 * epoch_idx\n",
    "    teacher_forcing = max(0, teacher_forcing)\n",
    "    writer.add_scalar('Params/teacher_forcing', teacher_forcing, iter_num)\n",
    "    writer.add_scalar('Params/beta', beta, iter_num)\n",
    "    for batch_idx, data_input in tqdm(enumerate(train_dataloader)):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        \n",
    "        # Discriminator\n",
    "        '''\n",
    "        gen_out, generated_highlight = G.sample(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = generated_highlight.permute(1, 0)\n",
    "        batch = torch.cat([generated_highlight, highlight.permute(1, 0)], dim=0)\n",
    "        targets = torch.tensor([0]*generated_highlight.size(0) + [1]*highlight.size(1)).to(device)\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        generator_optimizer.zero_grad()\n",
    "        out = D(batch)\n",
    "        loss = dis_criterion(out.squeeze(1), targets.float())\n",
    "        loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "        total_D_loss += loss.data.item() * highlight.size(1) * 2\n",
    "        iter_num += 1\n",
    "        writer.add_scalar('Loss/dis_adv_train', loss.data.item(), iter_num)\n",
    "        '''\n",
    "        iter_num += 1\n",
    "        \n",
    "        # Generator\n",
    "        generator_optimizer.zero_grad()\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        gen_out, generated_highlight = G.sample(article, highlight, teacher_forcing_ratio=teacher_forcing)\n",
    "        generated_highlight = generated_highlight.permute(1, 0)  # (batch_size, seq_len)\n",
    "        rollout_func = ROLLOUT(G)\n",
    "        rewards = rollout_func.get_reward(article, highlight.permute(1, 0), rollout_num, D)\n",
    "        writer.add_scalar('Reward/train', rewards.mean().data.item(), iter_num)\n",
    "        # rewards = 1 - rewards\n",
    "        pg_loss = G.batch_pgloss_generated(gen_out, highlight.permute(1, 0), rewards)\n",
    "        \n",
    "        out = G(article, highlight, teacher_forcing_ratio=teacher_forcing)\n",
    "        ml_loss = criterion_ml(out.permute(1, 2, 0), highlight.permute(1, 0))\n",
    "        \n",
    "        loss = beta*pg_loss + (1-beta)*ml_loss\n",
    "        loss.backward()\n",
    "        generator_optimizer.step()\n",
    "        writer.add_scalar('Loss_train/loss', loss.data.item(), iter_num)\n",
    "        writer.add_scalar('Loss_train/ml_loss', ml_loss.data.item(), iter_num)\n",
    "        writer.add_scalar('Loss_train/pg_loss', pg_loss.data.item(), iter_num)\n",
    "        total_G_loss += loss.data.item() * article.size(1)\n",
    "\n",
    "    G_losses.append(total_G_loss / len(train_dataset))\n",
    "    D_losses.append(total_D_loss / len(train_dataset) / 2)\n",
    "    print(f'epoch {epoch_idx} G loss: {G_losses[-1]}')\n",
    "    print(f'epoch {epoch_idx} D loss: {D_losses[-1]}')\n",
    "    \n",
    "    G.eval()\n",
    "    total_loss = 0.\n",
    "    total_reward = 0.\n",
    "    total_ml_loss = 0.\n",
    "    total_pg_loss = 0.\n",
    "    for batch_idx, data_input in tqdm(enumerate(val_dataloader), position=0, leave=True):\n",
    "        article = data_input[0].to(device)\n",
    "        highlight = data_input[1].to(device)\n",
    "        gen_out, generated_highlight = G.sample(article, highlight, teacher_forcing_ratio=0.)\n",
    "        generated_highlight = generated_highlight.permute(1, 0)  # (batch_size, seq_len)\n",
    "        rollout_func = ROLLOUT(G)\n",
    "        rewards = rollout_func.get_reward(article, highlight.permute(1, 0), rollout_num, D)\n",
    "        total_reward += rewards.mean().data.item() * article.size(1)\n",
    "        # rewards = 1 - rewards\n",
    "        pg_loss = G.batch_pgloss_generated(gen_out, highlight.permute(1, 0), rewards)\n",
    "        \n",
    "        out = G(article, highlight, teacher_forcing_ratio=0.)\n",
    "        ml_loss = criterion_ml(out.permute(1, 2, 0), highlight.permute(1, 0))\n",
    "        \n",
    "        loss = beta*pg_loss + (1-beta)*ml_loss\n",
    "        total_loss += loss.data.item() * article.size(1)\n",
    "        \n",
    "        total_ml_loss += ml_loss.data.item() * article.size(1)\n",
    "        total_pg_loss += pg_loss.data.item() * article.size(1)\n",
    "    writer.add_scalar('Reward/val', total_reward / len(val_dataset), iter_num)\n",
    "    writer.add_scalar('Loss_val/loss', total_loss / len(val_dataset), iter_num)\n",
    "    writer.add_scalar('Loss_val/ml_loss', total_ml_loss / len(val_dataset), iter_num)\n",
    "    writer.add_scalar('Loss_val/pg_loss', total_pg_loss / len(val_dataset), iter_num)\n",
    "    \n",
    "    scheduler.step(total_loss)\n",
    "    \n",
    "    G_ce_val_losses.append(total_loss / len(val_dataset))\n",
    "    print(f'epoch {epoch_idx} val loss: {G_ce_val_losses[-1]}')\n",
    "    # writer.add_scalar('Loss/gen_ce_val', G_ce_val_losses[-1], iter_num)\n",
    "    \n",
    "    \n",
    "    indices = sps.randint(0, out.size(1)).rvs(size=10)\n",
    "    pred_texts = tensor_to_text(out[:, indices, :], sp, beam_search=True)\n",
    "    truth_texts = tensor_to_text(highlight[:, indices], sp)\n",
    "    for pred, truth in zip(pred_texts, truth_texts):\n",
    "        writer.add_text('Texts/pred', pred, iter_num)\n",
    "        writer.add_text('Texts/truth', truth, iter_num)\n",
    "        print(f'predicted: {pred}')\n",
    "        print(f'truth: {truth}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'saved_models/dis9_adv.pth'\n",
    "torch.save(D.state_dict(), save_path)\n",
    "\n",
    "save_path = 'saved_models/gen9_adv.pth'\n",
    "torch.save(G.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
