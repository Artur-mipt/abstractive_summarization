{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.lstm_generator import LSTMGenerator\n",
    "from models.cnn_discriminator import CNNDiscriminator\n",
    "from models.rollout import ROLLOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### генератор: работает или нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 10\n",
    "hidden_dim = 20\n",
    "vocab_size = 100\n",
    "max_seq_len = 15\n",
    "padding_idx = 0\n",
    "G = LSTMGenerator(embedding_dim=emb_dim,\n",
    "                  hidden_dim=hidden_dim,\n",
    "                  vocab_size=vocab_size,\n",
    "                  max_seq_len=max_seq_len,\n",
    "                  padding_idx=padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMGenerator(\n",
       "  (embeddings): Embedding(100, 10, padding_idx=0)\n",
       "  (lstm): LSTM(10, 20, batch_first=True)\n",
       "  (lstm2out): Linear(in_features=20, out_features=100, bias=True)\n",
       "  (logsoftmax): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = max_seq_len\n",
    "batch = torch.randint(0, 100, size=(batch_size, seq_len))\n",
    "h = torch.zeros(1, batch_size, hidden_dim)\n",
    "c = torch.zeros(1, batch_size, hidden_dim)\n",
    "\n",
    "res = G(batch, (h, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 15, 100])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[78, 15, 79, 98, 96, 47,  6, 50, 34, 53, 35, 16, 67, 30, 59],\n",
       "        [41, 68, 84, 70, 27, 63, 24, 67, 10, 89, 13, 57, 91, 48, 89],\n",
       "        [70, 31,  8, 85, 58, 10, 99, 10, 52, 24, 77, 87, 43, 29,  2],\n",
       "        [62, 15,  6, 58, 11, 22, 72, 44, 63, 15, 36, 95, 34, 79,  1],\n",
       "        [32, 94, 57, 21, 80, 86, 63,  8, 32,  4, 74, 33,  8, 21,  7]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.sample(5, 5, start_letter=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### дискриминатор: работает или нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = G.sample(batch_size, batch_size, start_letter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = CNNDiscriminator(embed_dim=emb_dim,\n",
    "                     vocab_size=vocab_size,\n",
    "                     filter_sizes=[2, 3],\n",
    "                     num_filters=[2, 2],\n",
    "                     padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNDiscriminator(\n",
       "  (embeddings): Embedding(100, 10, padding_idx=0)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 2, kernel_size=(2, 10), stride=(1, 1))\n",
       "    (1): Conv2d(1, 2, kernel_size=(3, 10), stride=(1, 1))\n",
       "  )\n",
       "  (highway): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (feature2out): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = D(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6857, -0.1100],\n",
       "        [-0.8835, -0.1034],\n",
       "        [-0.5736, -0.0756],\n",
       "        [-0.0322,  0.0009],\n",
       "        [-0.0240, -0.1292],\n",
       "        [-0.5415, -0.0896],\n",
       "        [-0.0364, -0.0650],\n",
       "        [-0.9004, -0.1183],\n",
       "        [-0.0573, -0.1141],\n",
       "        [-0.1450, -0.1378],\n",
       "        [-0.7085, -0.0803],\n",
       "        [-0.6632, -0.1365],\n",
       "        [-0.7624, -0.1216],\n",
       "        [-0.4052, -0.1949],\n",
       "        [-0.1462, -0.1602],\n",
       "        [-0.3522, -0.0019],\n",
       "        [-0.7602, -0.0924],\n",
       "        [-0.3490, -0.0620],\n",
       "        [-0.5350, -0.1046],\n",
       "        [-0.2492, -0.0875],\n",
       "        [-0.8708, -0.1234],\n",
       "        [-0.7513, -0.1440],\n",
       "        [-0.1119, -0.0687],\n",
       "        [-0.6054, -0.1338],\n",
       "        [-0.8201, -0.1144],\n",
       "        [-0.4562, -0.0895],\n",
       "        [-0.1772,  0.0027],\n",
       "        [-0.6325, -0.1095],\n",
       "        [-0.7966, -0.0822],\n",
       "        [-0.5749,  0.0305],\n",
       "        [-0.5983, -0.0959],\n",
       "        [-0.3857, -0.1477]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward + backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_lr = 0.01\n",
    "discr_lr = 0.01\n",
    "\n",
    "gen_opt = torch.optim.Adam(G.parameters(),\n",
    "                           lr=gen_lr)\n",
    "gen_adv_opt = torch.optim.Adam(G.parameters(),\n",
    "                               lr=gen_lr)\n",
    "discr_opt = torch.optim.Adam(D.parameters(),\n",
    "                             lr=discr_lr)\n",
    "\n",
    "mle_criterion = nn.NLLLoss()\n",
    "dis_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pretrain generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "batch_size = 32\n",
    "seq_len = max_seq_len\n",
    "batch = torch.randint(0, 100, size=(batch_size, seq_len))\n",
    "h = torch.zeros(1, batch_size, hidden_dim)\n",
    "c = torch.zeros(1, batch_size, hidden_dim)\n",
    "\n",
    "target = torch.ones(batch_size, seq_len, dtype=torch.long)\n",
    "\n",
    "pred = G(batch, (h, c))  # (batch * seq) * vocab\n",
    "loss = mle_criterion(pred.permute(0, 2, 1), target)\n",
    "gen_opt.zero_grad()\n",
    "loss.backward()\n",
    "gen_opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pretrain discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_samples = torch.randint(0, 100, size=(batch_size, seq_len))\n",
    "neg_samples = G.sample(num_samples=batch_size,\n",
    "                       batch_size=batch_size, start_letter=0)\n",
    "inp = torch.cat((pos_samples, neg_samples), dim=0).long().detach()\n",
    "targets = torch.tensor([1]*batch_size + [0]*batch_size,\n",
    "                       dtype=torch.long)\n",
    "pred = D(inp)\n",
    "loss = dis_criterion(pred, targets)\n",
    "discr_opt.zero_grad()\n",
    "loss.backward()\n",
    "discr_opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**adversarial training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 15])\n"
     ]
    }
   ],
   "source": [
    "# train generator\n",
    "rollout_num = 20\n",
    "\n",
    "rollout_func = ROLLOUT(G)\n",
    "gen_inp = torch.randint(0, 100, size=(batch_size, seq_len))\n",
    "gen_target = torch.randint(0, 100, size=(batch_size, seq_len))\n",
    "rewards = rollout_func.get_reward(gen_target, rollout_num, D)\n",
    "print(rewards.shape)\n",
    "\n",
    "adv_loss = G.batchPGLoss(gen_inp, gen_target, rewards)\n",
    "gen_adv_opt.zero_grad()\n",
    "adv_loss.backward()\n",
    "gen_adv_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train discriminator\n",
    "pos_samples = torch.randint(0, 100, size=(batch_size, seq_len))\n",
    "neg_samples = G.sample(num_samples=batch_size,\n",
    "                       batch_size=batch_size, start_letter=0)\n",
    "inp = torch.cat((pos_samples, neg_samples), dim=0).long().detach()\n",
    "targets = torch.tensor([1]*batch_size + [0]*batch_size,\n",
    "                       dtype=torch.long)\n",
    "pred = D(inp)\n",
    "loss = dis_criterion(pred, targets)\n",
    "discr_opt.zero_grad()\n",
    "loss.backward()\n",
    "discr_opt.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
